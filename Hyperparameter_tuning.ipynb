{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYyjvnEWaNQo",
        "outputId": "a9e0a637-9dfd-4c2f-eb23-9eb09012f62f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "id": "uYyjvnEWaNQo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "608a53b9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from dateutil.parser import parse\n",
        "dateparse=lambda dates:parse(dates)\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import keras_tuner as kt \n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "import IPython\n",
        "import IPython.display"
      ],
      "id": "608a53b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73M6I9aqQuK4",
        "outputId": "8a9cb838-3b40-4952-d77d-e2d7166c1f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "73M6I9aqQuK4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnj9NoD39NZM"
      },
      "source": [
        "### Pre-processing dataset"
      ],
      "id": "Mnj9NoD39NZM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cff898f7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv ('drive/MyDrive/Data/weekly_features.csv')\n",
        "df = df.drop (columns = ['Unnamed: 0','USD_PHP Historical Data.csv'])\n",
        "dates = df.year*100+df.week\n",
        "df['Date'] = pd.to_datetime(dates.astype(str) + '0', format='%Y%W%w')\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
        "mask = (df['Date'] >'1990-09-30') & (df['Date'] <= '2021-09-30')\n",
        "df= df.loc[mask]\n",
        "df = df.fillna(method='ffill')\n",
        "\n",
        "def convert_to_timestamp(x):\n",
        "    \"\"\"Convert date objects to integers\"\"\"\n",
        "    return time.mktime(x.to_datetime().timetuple())\n",
        "\n",
        "# https://www.aiproblog.com/index.php/2018/08/21/4-common-machine-learning-data-transforms-for-time-series-forecasting/\n",
        "# difference dataset\n",
        "diff_df=df.drop(columns=['Date', 'year', 'week'])\n",
        "diff_df = diff_df.diff()\n",
        "diff_df = diff_df.iloc[1:]\n",
        "#diff_df['year']=df.year[1:]\n",
        "diff_df['week']=df.week[1:]\n",
        "#diff_df['Date']=df.Date[1:]\n",
        "#diff_df['Date'] = pd.to_datetime(diff_df['Date'])\n",
        "# convert date to timestamp\n",
        "#diff_df['Date'] = diff_df['Date'].map(pd.Timestamp.timestamp)\n",
        "\n",
        "#split the data into training and testing dataset\n",
        "column_indices = {name: i for i, name in enumerate(diff_df.columns)}\n",
        "\n",
        "n = len(diff_df)\n",
        "train_df = diff_df[0:int(n*0.7)]\n",
        "test_df = diff_df[int(n*0.7):]\n",
        "\n",
        "num_features = diff_df.shape[1]\n",
        "\n",
        "#Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#col_list = [i for i in diff_df.columns if i != 'Date']\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train = scaler.fit_transform(train_df)\n",
        "scaled_test = scaler.transform(test_df)"
      ],
      "id": "cff898f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cf94eb3"
      },
      "outputs": [],
      "source": [
        "raw_values = df.drop(columns=['year','week'])\n",
        "raw_values['Date'] = pd.to_datetime(raw_values['Date'])\n",
        "# convert date to timestamp\n",
        "raw_values['Date'] = raw_values['Date'].map(pd.Timestamp.timestamp)"
      ],
      "id": "1cf94eb3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cc5c338"
      },
      "outputs": [],
      "source": [
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i-history_size, i, step)\n",
        "        data.append(dataset[indices])\n",
        "\n",
        "        if single_step:\n",
        "            labels.append(target[i+target_size])\n",
        "        else:\n",
        "            labels.append(target[i:i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "id": "6cc5c338"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1BCNkpZQDDE"
      },
      "source": [
        "### Set up window"
      ],
      "id": "K1BCNkpZQDDE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmhUKMxHQBw4"
      },
      "outputs": [],
      "source": [
        "past_history = 20\n",
        "future_target = 15\n",
        "STEP = 1\n",
        "X, y = multivariate_data(scaled_train, scaled_train, 0,\n",
        "              None, past_history,\n",
        "              future_target, STEP,\n",
        "              single_step=False)\n",
        "\n",
        "X_test, y_test = multivariate_data(scaled_test, scaled_test, 0,\n",
        "                   None, past_history,\n",
        "                   future_target, STEP,\n",
        "                   single_step=False)\n",
        "test_data_multi= tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_data_multi = test_data_multi.batch(32).repeat()\n"
      ],
      "id": "UmhUKMxHQBw4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ScrYjVXswYU"
      },
      "outputs": [],
      "source": [
        "# Function of training models\n",
        "MAX_EPOCHS = 90\n",
        "EVALUATION_INTERVAL = 200\n",
        "batch_size = 32\n",
        "buffer_size = 150\n",
        "def compile_and_fit(model, train, val, patience=2):\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=patience,\n",
        "                                                    mode='min') \n",
        "\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                metrics=[tf.keras.losses.MeanSquaredError()])\n",
        "\n",
        "    history = model.fit(train, batch_size=batch_size, epochs=MAX_EPOCHS,\n",
        "                      validation_data=val,\n",
        "                        steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      callbacks=[early_stopping],\n",
        "                    validation_steps=10\n",
        "                       )\n",
        "    model.reset_states()\n",
        "    return history"
      ],
      "id": "5ScrYjVXswYU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoCIZ-DOQMj5"
      },
      "source": [
        "### Model"
      ],
      "id": "JoCIZ-DOQMj5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADXO16eWxzff"
      },
      "outputs": [],
      "source": [
        "class SampleModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = tf.keras.Sequential()\n",
        "        #model.add(tf.keras.layers.LSTM(units=hp.Int('units', min_value=20, max_value=600, step=20),return_sequences=True))\n",
        "        for i in range(hp.Int(\"n_cuDNNlstm_layers\",1,2)):\n",
        "          model.add(tf.compat.v1.keras.layers.CuDNNLSTM(units=hp.Int(f'lstm_{i}_units', min_value=192-128*i, max_value=384-256*i, step=32),return_sequences=True))\n",
        "          model.add(layers.Dropout(rate=hp.Float(f'lstm_{i}_dropout_rate', min_value=0.05, max_value=0.95, step=0.1)))\n",
        "\n",
        "        \n",
        "        for i in range(hp.Int(\"n_conv_layers\",1,2)):\n",
        "          model.add(layers.Conv1D(filters=hp.Int(f'conv_{i}_units', min_value=128-64*i, max_value=256-128*i, step=32), kernel_size=3, activation=\"relu\"))\n",
        "          model.add(layers.MaxPooling1D(pool_size=1))\n",
        "          model.add(layers.Dropout(rate=hp.Float(f'conv_{i}_dropout_rate', min_value=0.05, max_value=0.95, step=0.1)))\n",
        "        \n",
        "        model.add(layers.Flatten())\n",
        "       \n",
        "        for i in range(hp.Int(\"n_dense_layers\",1,2)):\n",
        "          model.add(layers.Dense(units=hp.Int(f'dense_{i}_units', min_value=384-256*i, max_value=512-256*i, step=32)))\n",
        "        model.add(layers.Dense(future_target*num_features,kernel_initializer=tf.initializers.zeros()))\n",
        "        model.add(layers.Reshape([future_target, num_features]))\n",
        "\n",
        "        model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate',\n",
        "                      values=[1e-3, 1e-4, 1e-5])),\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[tf.keras.losses.MeanSquaredError()])\n",
        "        \n",
        "        return model"
      ],
      "id": "ADXO16eWxzff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLSpBxf19ouE",
        "outputId": "956b45d4-ac95-49b1-dc49-398489cde355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 60 Complete [00h 00m 41s]\n",
            "val_loss: 0.025289083644747735\n",
            "\n",
            "Best val_loss So Far: 0.007745090406388044\n",
            "Total elapsed time: 00h 52m 32s\n",
            "{'n_cuDNNlstm_layers': 1, 'lstm_0_units': 320, 'lstm_0_dropout_rate': 0.05, 'n_conv_layers': 2, 'conv_0_units': 192, 'conv_0_dropout_rate': 0.25000000000000006, 'n_dense_layers': 2, 'dense_0_units': 416, 'learning_rate': 0.001, 'epochs': 80, 'lstm_1_units': 96, 'lstm_1_dropout_rate': 0.45000000000000007, 'conv_1_units': 96, 'conv_1_dropout_rate': 0.45000000000000007, 'dense_1_units': 256}\n"
          ]
        }
      ],
      "source": [
        "## trail.hyperparamter is replaced by hp\n",
        "buffer_size = 150\n",
        "\n",
        "class CVTuner(kt.engine.tuner.Tuner):\n",
        "    def run_trial(self, trial, x, y, *args, **kwargs):\n",
        "        splits = TimeSeriesSplit(n_splits=5)\n",
        "        val_losses = []\n",
        "        batch_size = 32\n",
        "        epochs = trial.hyperparameters.Int('epochs', 10, 100, step=10)\n",
        "\n",
        "        for train_indices, test_indices in splits.split(x):\n",
        "            x_train, x_val = x[train_indices], x[test_indices]\n",
        "            y_train, y_val = y[train_indices], y[test_indices]\n",
        "\n",
        "            train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "            train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
        "\n",
        "            val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "            val_data = val_data.batch(batch_size).repeat()\n",
        "    \n",
        "            model = self.hypermodel.build(trial.hyperparameters)\n",
        "            model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "            val_loss= model.evaluate(x_val, y_val)\n",
        "            val_losses.append(val_loss[1])\n",
        "        \n",
        "        \n",
        "        self.oracle.update_trial(trial.trial_id, {'val_loss': np.mean(val_losses)})\n",
        "        #self.save_model(trial.trial_id, model)\n",
        "\n",
        "\n",
        "model = SampleModel()\n",
        "tuner = CVTuner(oracle=kt.oracles.RandomSearch(objective='val_loss',max_trials=60), hypermodel=model, directory='drive/MyDrive/Data', project_name = 'LSTM_CNN_encoder', executions_per_trial=2, overwrite = True)\n",
        "\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, mode='min') \n",
        "\n",
        "tuner.search(X, y, callbacks=[early_stopping])\n",
        "\n",
        "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "print(best_hyperparameters.values)\n",
        "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
        "#best_model.summary()"
      ],
      "id": "qLSpBxf19ouE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji-62pNApPPC",
        "outputId": "774fd8bd-fc7d-437e-e602-7ad59d2c8ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in drive/MyDrive/Data/LSTM_CNN_encoder\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f7e9512cc50>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 320\n",
            "lstm_0_dropout_rate: 0.05\n",
            "n_conv_layers: 2\n",
            "conv_0_units: 192\n",
            "conv_0_dropout_rate: 0.25000000000000006\n",
            "n_dense_layers: 2\n",
            "dense_0_units: 416\n",
            "learning_rate: 0.001\n",
            "epochs: 80\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.45000000000000007\n",
            "conv_1_units: 96\n",
            "conv_1_dropout_rate: 0.45000000000000007\n",
            "dense_1_units: 256\n",
            "Score: 0.007745090406388044\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 224\n",
            "lstm_0_dropout_rate: 0.25000000000000006\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 160\n",
            "conv_0_dropout_rate: 0.25000000000000006\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 480\n",
            "learning_rate: 0.001\n",
            "epochs: 80\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.8500000000000002\n",
            "conv_1_units: 128\n",
            "conv_1_dropout_rate: 0.7500000000000002\n",
            "Score: 0.007887329161167144\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 2\n",
            "lstm_0_units: 224\n",
            "lstm_0_dropout_rate: 0.5500000000000002\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 224\n",
            "conv_0_dropout_rate: 0.6500000000000001\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 448\n",
            "learning_rate: 0.001\n",
            "epochs: 90\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.15000000000000002\n",
            "conv_1_units: 96\n",
            "conv_1_dropout_rate: 0.6500000000000001\n",
            "dense_1_units: 192\n",
            "Score: 0.00802707988768816\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 224\n",
            "lstm_0_dropout_rate: 0.25000000000000006\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 128\n",
            "conv_0_dropout_rate: 0.35000000000000003\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 384\n",
            "learning_rate: 0.001\n",
            "epochs: 60\n",
            "lstm_1_units: 64\n",
            "lstm_1_dropout_rate: 0.25000000000000006\n",
            "conv_1_units: 128\n",
            "conv_1_dropout_rate: 0.8500000000000002\n",
            "dense_1_units: 224\n",
            "Score: 0.00803322046995163\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 256\n",
            "lstm_0_dropout_rate: 0.05\n",
            "n_conv_layers: 2\n",
            "conv_0_units: 128\n",
            "conv_0_dropout_rate: 0.15000000000000002\n",
            "n_dense_layers: 2\n",
            "dense_0_units: 512\n",
            "learning_rate: 0.001\n",
            "epochs: 80\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.05\n",
            "conv_1_units: 96\n",
            "conv_1_dropout_rate: 0.25000000000000006\n",
            "dense_1_units: 128\n",
            "Score: 0.008265944942831994\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 384\n",
            "lstm_0_dropout_rate: 0.05\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 128\n",
            "conv_0_dropout_rate: 0.6500000000000001\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 384\n",
            "learning_rate: 0.001\n",
            "epochs: 50\n",
            "lstm_1_units: 128\n",
            "lstm_1_dropout_rate: 0.6500000000000001\n",
            "conv_1_units: 64\n",
            "conv_1_dropout_rate: 0.7500000000000002\n",
            "dense_1_units: 224\n",
            "Score: 0.008339188154786825\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 320\n",
            "lstm_0_dropout_rate: 0.35000000000000003\n",
            "n_conv_layers: 2\n",
            "conv_0_units: 160\n",
            "conv_0_dropout_rate: 0.7500000000000002\n",
            "n_dense_layers: 2\n",
            "dense_0_units: 416\n",
            "learning_rate: 0.001\n",
            "epochs: 70\n",
            "lstm_1_units: 128\n",
            "lstm_1_dropout_rate: 0.45000000000000007\n",
            "conv_1_units: 64\n",
            "conv_1_dropout_rate: 0.8500000000000002\n",
            "dense_1_units: 224\n",
            "Score: 0.00872398829087615\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 352\n",
            "lstm_0_dropout_rate: 0.35000000000000003\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 224\n",
            "conv_0_dropout_rate: 0.15000000000000002\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 512\n",
            "learning_rate: 0.001\n",
            "epochs: 50\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.25000000000000006\n",
            "conv_1_units: 96\n",
            "conv_1_dropout_rate: 0.15000000000000002\n",
            "dense_1_units: 224\n",
            "Score: 0.008901266288012267\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 352\n",
            "lstm_0_dropout_rate: 0.5500000000000002\n",
            "n_conv_layers: 1\n",
            "conv_0_units: 160\n",
            "conv_0_dropout_rate: 0.35000000000000003\n",
            "n_dense_layers: 1\n",
            "dense_0_units: 480\n",
            "learning_rate: 0.001\n",
            "epochs: 60\n",
            "lstm_1_units: 96\n",
            "lstm_1_dropout_rate: 0.9500000000000002\n",
            "conv_1_units: 96\n",
            "conv_1_dropout_rate: 0.35000000000000003\n",
            "dense_1_units: 192\n",
            "Score: 0.009505326673388482\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_cuDNNlstm_layers: 1\n",
            "lstm_0_units: 256\n",
            "lstm_0_dropout_rate: 0.25000000000000006\n",
            "n_conv_layers: 2\n",
            "conv_0_units: 224\n",
            "conv_0_dropout_rate: 0.15000000000000002\n",
            "n_dense_layers: 2\n",
            "dense_0_units: 448\n",
            "learning_rate: 0.001\n",
            "epochs: 30\n",
            "lstm_1_units: 128\n",
            "lstm_1_dropout_rate: 0.05\n",
            "conv_1_units: 128\n",
            "conv_1_dropout_rate: 0.35000000000000003\n",
            "dense_1_units: 160\n",
            "Score: 0.009726025629788637\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ],
      "id": "ji-62pNApPPC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJYghC0b8ljN"
      },
      "source": [],
      "id": "XJYghC0b8ljN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ7dZMPEk3k9",
        "outputId": "7ff12eee-18f2-49ca-c037-fdaa6cdc8bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in drive/MyDrive/Data/LSTM_CNN\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f91ccf02490>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 416\n",
            "lstm_dropout_rate: 0.25000000000000006\n",
            "conv__units: 192\n",
            "conv_dropout_rate: 0.05\n",
            "dense_units: 160\n",
            "learning_rate: 0.0001\n",
            "epochs: 80\n",
            "Score: 0.010465066228061915\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 448\n",
            "lstm_dropout_rate: 0.35000000000000003\n",
            "conv__units: 352\n",
            "conv_dropout_rate: 0.5500000000000002\n",
            "dense_units: 256\n",
            "learning_rate: 0.0001\n",
            "epochs: 80\n",
            "Score: 0.010500004049390554\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 192\n",
            "lstm_dropout_rate: 0.45000000000000007\n",
            "conv__units: 96\n",
            "conv_dropout_rate: 0.45000000000000007\n",
            "dense_units: 512\n",
            "learning_rate: 0.0001\n",
            "epochs: 70\n",
            "Score: 0.010581668466329575\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 480\n",
            "lstm_dropout_rate: 0.35000000000000003\n",
            "conv__units: 480\n",
            "conv_dropout_rate: 0.8500000000000002\n",
            "dense_units: 384\n",
            "learning_rate: 0.0001\n",
            "epochs: 70\n",
            "Score: 0.010952244326472283\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 256\n",
            "lstm_dropout_rate: 0.15000000000000002\n",
            "conv__units: 416\n",
            "conv_dropout_rate: 0.7500000000000002\n",
            "dense_units: 480\n",
            "learning_rate: 0.0001\n",
            "epochs: 50\n",
            "Score: 0.011016341857612133\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 256\n",
            "lstm_dropout_rate: 0.5500000000000002\n",
            "conv__units: 192\n",
            "conv_dropout_rate: 0.6500000000000001\n",
            "dense_units: 384\n",
            "learning_rate: 0.0001\n",
            "epochs: 70\n",
            "Score: 0.011121007055044175\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 96\n",
            "lstm_dropout_rate: 0.35000000000000003\n",
            "conv__units: 416\n",
            "conv_dropout_rate: 0.6500000000000001\n",
            "dense_units: 96\n",
            "learning_rate: 0.0001\n",
            "epochs: 90\n",
            "Score: 0.011877305619418622\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 160\n",
            "lstm_dropout_rate: 0.15000000000000002\n",
            "conv__units: 352\n",
            "conv_dropout_rate: 0.5500000000000002\n",
            "dense_units: 128\n",
            "learning_rate: 0.0001\n",
            "epochs: 60\n",
            "Score: 0.012683635763823985\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 224\n",
            "lstm_dropout_rate: 0.35000000000000003\n",
            "conv__units: 448\n",
            "conv_dropout_rate: 0.35000000000000003\n",
            "dense_units: 352\n",
            "learning_rate: 0.0001\n",
            "epochs: 30\n",
            "Score: 0.013169948011636734\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "lstm_units: 160\n",
            "lstm_dropout_rate: 0.15000000000000002\n",
            "conv__units: 192\n",
            "conv_dropout_rate: 0.45000000000000007\n",
            "dense_units: 64\n",
            "learning_rate: 0.0001\n",
            "epochs: 80\n",
            "Score: 0.013278277777135371\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ],
      "id": "vZ7dZMPEk3k9"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Hyperparameter tuning.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}