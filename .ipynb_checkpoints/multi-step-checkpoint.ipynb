{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4450d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dateutil.parser import parse\n",
    "dateparse=lambda dates:parse(dates)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df29ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('Data/weekly_features.csv')\n",
    "df = df.drop (columns = ['Unnamed: 0','USD_PHP Historical Data.csv'])\n",
    "dates = df.year*100+df.week\n",
    "df['Date'] = pd.to_datetime(dates.astype(str) + '0', format='%Y%W%w')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "mask = (df['Date'] >'1990-09-30') & (df['Date'] <= '2021-09-30')\n",
    "df= df.loc[mask]\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "def convert_to_timestamp(x):\n",
    "    \"\"\"Convert date objects to integers\"\"\"\n",
    "    return time.mktime(x.to_datetime().timetuple())\n",
    "\n",
    "# https://www.aiproblog.com/index.php/2018/08/21/4-common-machine-learning-data-transforms-for-time-series-forecasting/\n",
    "# difference dataset\n",
    "diff_df=df.drop(columns=['Date', 'year', 'week'])\n",
    "diff_df = diff_df.diff()\n",
    "diff_df = diff_df.iloc[1:]\n",
    "diff_df['year']=df.year[1:]\n",
    "diff_df['week']=df.year[1:]\n",
    "#diff_df['Date']=df.Date[1:]\n",
    "#diff_df['Date'] = pd.to_datetime(diff_df['Date'])\n",
    "# convert date to timestamp\n",
    "#diff_df['Date'] = diff_df['Date'].map(pd.Timestamp.timestamp)\n",
    "\n",
    "#split the data into training and testing dataset\n",
    "column_indices = {name: i for i, name in enumerate(diff_df.columns)}\n",
    "\n",
    "n = len(diff_df)\n",
    "train_df = diff_df[0:int(n*0.7)]\n",
    "test_df = diff_df[int(n*0.7):]\n",
    "\n",
    "num_features = diff_df.shape[1]\n",
    "\n",
    "#Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#col_list = [i for i in diff_df.columns if i != 'Date']\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_df)\n",
    "scaled_test = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d446dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data = scaled_train, columns = ['tmax','tmin','prcp','Crude Oil WTI', 'Gold','Oats','Corn','Soybeans','Wheat','USD_CAD','USD_CNY','USD_EUR','USD_MXN','SWE','SNOW','SNWD','year','week'])\n",
    "test_df = pd.DataFrame(data = scaled_test, columns = ['tmax','tmin','prcp','Crude Oil WTI', 'Gold','Oats','Corn','Soybeans','Wheat','USD_CAD','USD_CNY','USD_EUR','USD_MXN','SWE','SNOW','SNWD','year', 'week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc5b57",
   "metadata": {},
   "source": [
    "#### raw values generate from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values = df.drop(columns=['Date'])\n",
    "#raw_values['Date'] = pd.to_datetime(raw_values['Date'])\n",
    "# convert date to timestamp\n",
    "#raw_values['Date'] = raw_values['Date'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ce58e",
   "metadata": {},
   "source": [
    "### sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205b7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded32a2",
   "metadata": {},
   "source": [
    "### compile and fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc55456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of training models\n",
    "MAX_EPOCHS = 100\n",
    "EVALUATION_INTERVAL = 200\n",
    "batch_size = 32\n",
    "buffer_size = 150\n",
    "def compile_and_fit(model, train, val, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min') \n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.losses.MeanSquaredError()])\n",
    "\n",
    "    history = model.fit(train, batch_size=batch_size, epochs=MAX_EPOCHS,\n",
    "                      validation_data=val,\n",
    "                        steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      callbacks=[early_stopping],\n",
    "                    validation_steps=10\n",
    "                       )\n",
    "    model.reset_states()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X, past_history):\n",
    "    X = X.reshape(1, past_history, num_features)\n",
    "    yhat = model.predict(X)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74329874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_difference(history, yhat, position=1):\n",
    "    return yhat + history[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81985b",
   "metadata": {},
   "source": [
    "### set up window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5bfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 20\n",
    "future_target = 5\n",
    "STEP = 1\n",
    "X_multi, y_multi = multivariate_data(scaled_train, scaled_train, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "X_test_multi, y_test_multi = multivariate_data(scaled_test, scaled_test, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "test_data_multi= tf.data.Dataset.from_tensor_slices((X_test_multi, y_test_multi))\n",
    "test_data_multi = test_data_multi.batch(batch_size).repeat()\n",
    "\n",
    "multi_val_performance = {}\n",
    "multi_test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1281b27",
   "metadata": {},
   "source": [
    "### split data into multiple training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b30faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Observations: 376\n",
      "Training Observations: 189\n",
      "Testing Observations: 187\n",
      "\n",
      "\n",
      "Fold: 1\n",
      "Observations: 563\n",
      "Training Observations: 376\n",
      "Testing Observations: 187\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Observations: 750\n",
      "Training Observations: 563\n",
      "Testing Observations: 187\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Observations: 937\n",
      "Training Observations: 750\n",
      "Testing Observations: 187\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Observations: 1124\n",
      "Training Observations: 937\n",
      "Testing Observations: 187\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/tomwarrens/timeseriessplit-how-to-use-it/notebook \n",
    "splits = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    X_train, X_val = X_multi[train_index], X_multi[test_index]\n",
    "    #X_train, X_val = scaled_train[train_index], scaled_train[test_index]\n",
    "    #print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "    print('Observations: %d' % (len(X_train) + len(X_val)))\n",
    "    print('Training Observations: %d' % (len(X_train)))\n",
    "    print('Testing Observations: %d' % (len(X_val)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492169b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22132527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return tf.tile(inputs[:, -1:, :], [1, future_target, 1])\n",
    "\n",
    "baseline = MultiStepLastBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c832b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    print(y_train_multi.shape)\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = baseline.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['Baseline'] = Mean_mae\n",
    "multi_test_performance['Baseline'] = baseline.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f88a5",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1a7678e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "arima_mse = []\n",
    "for i in range(num_features):\n",
    "    model1 = pm.ARIMA(order=(2, 1, 0))\n",
    "    #model2 = pm.ARIMA(order=(1, 1, 2),\n",
    "                  #seasonal_order=(0, 1, 1, 12),\n",
    "                  #suppress_warnings=True)\n",
    "    cv = model_selection.SlidingWindowForecastCV(window_size=20, step=1, h=20)\n",
    "    model1_cv_scores = model_selection.cross_val_score(\n",
    "    model1, scaled_train[:453,i], scoring='mean_squared_error', cv=cv, verbose=2)\n",
    "    m1_average_error = np.average(model1_cv_scores)\n",
    "    arima_mse.append(m1_average_error)\n",
    "IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d6cbb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028318601444386877"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(arima_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800f6c7",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bfb12bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(future_target*num_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4af5c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_lstm_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_lstm_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['LSTM'] = Mean_mae\n",
    "multi_test_performance['LSTM'] = multi_lstm_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da92cd6",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b20ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, dense_units]\n",
    "    #tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(future_target*num_features,kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdf9659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_conv_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_conv_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN'] = Mean_mae\n",
    "multi_test_performance['CNN'] = multi_conv_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7b274",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65710c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cnn_lstm = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.Conv1D(filters=384, kernel_size=3, activation='relu', input_shape=(past_history, num_features)),\n",
    "    tf.keras.layers.Conv1D(filters=384, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.RepeatVector(future_target),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(rate = 0.25),\n",
    "    tf.keras.layers.LSTM(96, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate = 0.25),\n",
    "    #tf.compat.v1.keras.layers.CuDNNLSTM(200,return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(128, activation='relu')),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68317db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m evaluation_val_list \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msplits\u001b[49m\u001b[38;5;241m.\u001b[39msplit(X_multi)):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fold))\n\u001b[0;32m      4\u001b[0m     x_train_multi, x_val_multi \u001b[38;5;241m=\u001b[39m X_multi[train_index], X_multi[test_index]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_cnn_lstm, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_cnn_lstm.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN-LSTM'] = Mean_mae\n",
    "multi_test_performance['CNN-LSTM'] = multi_cnn_lstm.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66acf46",
   "metadata": {},
   "source": [
    "### LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501f991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(256,input_shape= (past_history,num_features), return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate = 0.25),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    #tf.keras.layers.Dense(future_target*num_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    #tf.keras.layers.Reshape([future_target, num_features]) \n",
    "    #tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Conv1D(filters=192, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=1),\n",
    "    tf.keras.layers.Dropout(rate = 0.75),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(448),\n",
    "    tf.keras.layers.Dense(future_target*num_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([future_target, num_features])   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9bd89ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 20, 256)           280576    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 20, 256)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 18, 192)           147648    \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 18, 192)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 18, 192)           0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 3456)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 448)               1548736   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 85)                38165     \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 5, 17)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,015,125\n",
      "Trainable params: 2,015,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_lstm_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f402a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 10s 59ms/step - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0061 - mean_squared_error: 0.0062\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0056 - mean_squared_error: 0.0055\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0055 - mean_squared_error: 0.0056\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0054 - mean_squared_error: 0.0055\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0053 - mean_squared_error: 0.0052\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.0051 - mean_squared_error: 0.0050\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0051 - mean_squared_error: 0.0052\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0050 - mean_squared_error: 0.0049\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0049 - mean_squared_error: 0.0048\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0048 - mean_squared_error: 0.0049\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0049 - mean_squared_error: 0.0050\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0049 - mean_squared_error: 0.0048\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0049 - mean_squared_error: 0.0048\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0048 - mean_squared_error: 0.0047\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0048 - mean_squared_error: 0.0049\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0047 - mean_squared_error: 0.0049\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.0048 - mean_squared_error: 0.0047\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0050 - mean_squared_error: 0.0049\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0048 - mean_squared_error: 0.0047\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0047 - mean_squared_error: 0.0048\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0046 - mean_squared_error: 0.0045\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n"
     ]
    }
   ],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_lstm_cnn, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_lstm_cnn.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['LSTM-CNN'] = Mean_mae\n",
    "\n",
    "multi_lstm_cnn.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.losses.MeanSquaredError()])\n",
    "history = multi_lstm_cnn.fit(X_multi, y_multi, batch_size=batch_size, epochs=MAX_EPOCHS,\n",
    "                    validation_steps=10\n",
    "                       )\n",
    "multi_test_performance['LSTM-CNN'] = multi_lstm_cnn.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f38ba8",
   "metadata": {},
   "source": [
    "### plot MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d11e972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(multi_test_performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_squared_error'\n",
    "metric_index = multi_lstm_cnn.metrics_names.index('mean_squared_error')\n",
    "val_mae = [v for v in multi_val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in multi_test_performance.values()]\n",
    "\n",
    "pyplot.ylabel('mean_squared_error')\n",
    "pyplot.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "pyplot.bar(x + 0.17, test_mae, width, label='Test')\n",
    "pyplot.xticks(ticks=x, labels=multi_test_performance.keys(),\n",
    "           rotation=45)\n",
    "_ = pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f69b8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LSTM-CNN': [0.009554349817335606, 0.00965628121048212]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_test_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
