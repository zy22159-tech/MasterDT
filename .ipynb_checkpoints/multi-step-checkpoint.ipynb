{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4450d6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangz\\AppData\\Local\\Temp\\ipykernel_30716\\871270155.py:12: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dateutil.parser import parse\n",
    "dateparse=lambda dates:parse(dates)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "import IPython\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df29ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('Data/weekly_features.csv')\n",
    "df = df.drop (columns = ['Unnamed: 0','USD_PHP Historical Data.csv'])\n",
    "dates = df.year*100+df.week\n",
    "df['Date'] = pd.to_datetime(dates.astype(str) + '0', format='%Y%W%w')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "mask = (df['Date'] >'1990-09-30') & (df['Date'] <= '2021-09-30')\n",
    "df= df.loc[mask]\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "def convert_to_timestamp(x):\n",
    "    \"\"\"Convert date objects to integers\"\"\"\n",
    "    return time.mktime(x.to_datetime().timetuple())\n",
    "\n",
    "# https://www.aiproblog.com/index.php/2018/08/21/4-common-machine-learning-data-transforms-for-time-series-forecasting/\n",
    "# difference dataset\n",
    "diff_df=df.drop(columns=['Date', 'year', 'week'])\n",
    "diff_df = diff_df.diff()\n",
    "diff_df = diff_df.iloc[1:]\n",
    "#diff_df['year']=df.year[1:]\n",
    "#diff_df['week']=df.year[1:]\n",
    "diff_df['Date']=df.Date[1:]\n",
    "diff_df['Date'] = pd.to_datetime(diff_df['Date'])\n",
    "# convert date to timestamp\n",
    "diff_df['Date'] = diff_df['Date'].map(pd.Timestamp.timestamp)\n",
    "\n",
    "#split the data into training and testing dataset\n",
    "column_indices = {name: i for i, name in enumerate(diff_df.columns)}\n",
    "\n",
    "n = len(diff_df)\n",
    "train_df = diff_df[0:int(n*0.7)]\n",
    "test_df = diff_df[int(n*0.7):]\n",
    "\n",
    "num_features = diff_df.shape[1]\n",
    "\n",
    "#Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#col_list = [i for i in diff_df.columns if i != 'Date']\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_df)\n",
    "scaled_test = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc5b57",
   "metadata": {},
   "source": [
    "#### raw values generate from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values = df.drop(columns=['year','week'])\n",
    "raw_values['Date'] = pd.to_datetime(raw_values['Date'])\n",
    "# convert date to timestamp\n",
    "raw_values['Date'] = raw_values['Date'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ce58e",
   "metadata": {},
   "source": [
    "### sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205b7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded32a2",
   "metadata": {},
   "source": [
    "### compile and fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc55456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of training models\n",
    "MAX_EPOCHS = 20\n",
    "EVALUATION_INTERVAL = 200\n",
    "batch_size = 32\n",
    "buffer_size = 150\n",
    "def compile_and_fit(model, train, val, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min') \n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(train, batch_size=batch_size, epochs=MAX_EPOCHS,\n",
    "                      validation_data=val,\n",
    "                        steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      callbacks=[early_stopping],\n",
    "                    validation_steps=10\n",
    "                       )\n",
    "    model.reset_states()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X, past_history):\n",
    "    X = X.reshape(1, past_history, num_features)\n",
    "    yhat = model.predict(X)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74329874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_difference(history, yhat, position=1):\n",
    "    return yhat + history[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81985b",
   "metadata": {},
   "source": [
    "### set up window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd5bfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 7\n",
    "future_target = 5\n",
    "STEP = 1\n",
    "X_multi, y_multi = multivariate_data(scaled_train, scaled_train, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "X_test_multi, y_test_multi = multivariate_data(scaled_test, scaled_test, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "test_data_multi= tf.data.Dataset.from_tensor_slices((X_test_multi, y_test_multi))\n",
    "test_data_multi = test_data_multi.batch(batch_size).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3978b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_val_performance = {}\n",
    "multi_test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1281b27",
   "metadata": {},
   "source": [
    "### split data into multiple training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b30faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Observations: 381\n",
      "Training Observations: 191\n",
      "Testing Observations: 190\n",
      "\n",
      "\n",
      "Fold: 1\n",
      "Observations: 571\n",
      "Training Observations: 381\n",
      "Testing Observations: 190\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Observations: 761\n",
      "Training Observations: 571\n",
      "Testing Observations: 190\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Observations: 951\n",
      "Training Observations: 761\n",
      "Testing Observations: 190\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Observations: 1141\n",
      "Training Observations: 951\n",
      "Testing Observations: 190\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/tomwarrens/timeseriessplit-how-to-use-it/notebook \n",
    "splits = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    X_train, X_val = X_multi[train_index], X_multi[test_index]\n",
    "    #X_train, X_val = scaled_train[train_index], scaled_train[test_index]\n",
    "    #print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "    print('Observations: %d' % (len(X_train) + len(X_val)))\n",
    "    print('Training Observations: %d' % (len(X_train)))\n",
    "    print('Testing Observations: %d' % (len(X_val)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492169b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22132527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return tf.tile(inputs[:, -1:, :], [1, future_target, 1])\n",
    "\n",
    "baseline = MultiStepLastBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c832b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "    print(y_train_multi.shape)\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = baseline.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['Baseline'] = Mean_mae\n",
    "multi_test_performance['Baseline'] = baseline.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f1b2e",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfb12bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(future_target*num_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4af5c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_lstm_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_lstm_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['LSTM'] = Mean_mae\n",
    "multi_test_performance['LSTM'] = multi_lstm_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da92cd6",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29b20ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, dense_units]\n",
    "    #tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(future_target*num_features,kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdf9659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_conv_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_conv_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN'] = Mean_mae\n",
    "multi_test_performance['CNN'] = multi_conv_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7b274",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65710c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cnn_lstm = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.Conv1D(filters=512, kernel_size=3, activation='relu', input_shape=(past_history, num_features)),\n",
    "    tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.RepeatVector(future_target),\n",
    "    tf.keras.layers.LSTM(200, return_sequences=True),\n",
    "    #tf.compat.v1.keras.layers.CuDNNLSTM(200,return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu')),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c68317db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_cnn_lstm, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_cnn_lstm.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN-LSTM'] = Mean_mae\n",
    "multi_test_performance['CNN-LSTM'] = multi_cnn_lstm.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f38ba8",
   "metadata": {},
   "source": [
    "### plot MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d11e972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(multi_test_performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = baseline.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v for v in multi_val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in multi_test_performance.values()]\n",
    "\n",
    "pyplot.ylabel('mean_absolute_error')\n",
    "pyplot.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "pyplot.bar(x + 0.17, test_mae, width, label='Test')\n",
    "pyplot.xticks(ticks=x, labels=multi_test_performance.keys(),\n",
    "           rotation=45)\n",
    "_ = pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44df9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
