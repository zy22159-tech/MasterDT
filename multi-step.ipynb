{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4450d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from dateutil.parser import parse\n",
    "dateparse=lambda dates:parse(dates)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "\n",
    "import IPython\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df29ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('Data/weekly_features.csv')\n",
    "df = df.drop (columns = ['Unnamed: 0','USD_PHP Historical Data.csv'])\n",
    "dates = df.year*100+df.week\n",
    "df['Date'] = pd.to_datetime(dates.astype(str) + '0', format='%Y%W%w')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "mask = (df['Date'] >'1990-09-30') & (df['Date'] <= '2021-09-30')\n",
    "df= df.loc[mask]\n",
    "df = df.fillna(method='ffill')\n",
    "\n",
    "def convert_to_timestamp(x):\n",
    "    \"\"\"Convert date objects to integers\"\"\"\n",
    "    return time.mktime(x.to_datetime().timetuple())\n",
    "\n",
    "# https://www.aiproblog.com/index.php/2018/08/21/4-common-machine-learning-data-transforms-for-time-series-forecasting/\n",
    "# difference dataset\n",
    "diff_df=df.drop(columns=['Date', 'year', 'week'])\n",
    "diff_df = diff_df.diff()\n",
    "diff_df = diff_df.iloc[1:]\n",
    "#diff_df['year']=df.year[1:]\n",
    "#diff_df['week']=df.year[1:]\n",
    "diff_df['Date']=df.Date[1:]\n",
    "diff_df['Date'] = pd.to_datetime(diff_df['Date'])\n",
    "# convert date to timestamp\n",
    "diff_df['Date'] = diff_df['Date'].map(pd.Timestamp.timestamp)\n",
    "\n",
    "#split the data into training and testing dataset\n",
    "column_indices = {name: i for i, name in enumerate(diff_df.columns)}\n",
    "\n",
    "n = len(diff_df)\n",
    "train_df = diff_df[0:int(n*0.7)]\n",
    "test_df = diff_df[int(n*0.7):]\n",
    "\n",
    "num_features = diff_df.shape[1]\n",
    "\n",
    "#Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#col_list = [i for i in diff_df.columns if i != 'Date']\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(train_df)\n",
    "scaled_test = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc5b57",
   "metadata": {},
   "source": [
    "#### raw values generate from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_values = df.drop(columns=['year','week'])\n",
    "raw_values['Date'] = pd.to_datetime(raw_values['Date'])\n",
    "# convert date to timestamp\n",
    "raw_values['Date'] = raw_values['Date'].map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ce58e",
   "metadata": {},
   "source": [
    "### sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205b7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded32a2",
   "metadata": {},
   "source": [
    "### compile and fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc55456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of training models\n",
    "MAX_EPOCHS = 20\n",
    "EVALUATION_INTERVAL = 200\n",
    "batch_size = 32\n",
    "buffer_size = 150\n",
    "def compile_and_fit(model, train, val, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min') \n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(train, batch_size=batch_size, epochs=MAX_EPOCHS,\n",
    "                      validation_data=val,\n",
    "                        steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      callbacks=[early_stopping],\n",
    "                    validation_steps=10\n",
    "                       )\n",
    "    model.reset_states()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5648d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X, past_history):\n",
    "    X = X.reshape(1, past_history, num_features)\n",
    "    yhat = model.predict(X)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74329874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_difference(history, yhat, position=1):\n",
    "    return yhat + history[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81985b",
   "metadata": {},
   "source": [
    "### set up window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd5bfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 7\n",
    "future_target = 5\n",
    "STEP = 1\n",
    "X_multi, y_multi = multivariate_data(scaled_train, scaled_train, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "X_test_multi, y_test_multi = multivariate_data(scaled_test, scaled_test, 0,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "test_data_multi= tf.data.Dataset.from_tensor_slices((X_test_multi, y_test_multi))\n",
    "test_data_multi = test_data_multi.batch(batch_size).repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3978b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_val_performance = {}\n",
    "multi_test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1281b27",
   "metadata": {},
   "source": [
    "### split data into multiple training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b30faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Observations: 381\n",
      "Training Observations: 192\n",
      "Testing Observations: 189\n",
      "\n",
      "\n",
      "Fold: 1\n",
      "Observations: 570\n",
      "Training Observations: 381\n",
      "Testing Observations: 189\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Observations: 759\n",
      "Training Observations: 570\n",
      "Testing Observations: 189\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Observations: 948\n",
      "Training Observations: 759\n",
      "Testing Observations: 189\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Observations: 1137\n",
      "Training Observations: 948\n",
      "Testing Observations: 189\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/tomwarrens/timeseriessplit-how-to-use-it/notebook \n",
    "splits = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    X_train, X_val = X_multi[train_index], X_multi[test_index]\n",
    "    #X_train, X_val = scaled_train[train_index], scaled_train[test_index]\n",
    "    #print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "    print('Observations: %d' % (len(X_train) + len(X_val)))\n",
    "    print('Training Observations: %d' % (len(X_train)))\n",
    "    print('Testing Observations: %d' % (len(X_val)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492169b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22132527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepLastBaseline(tf.keras.Model):\n",
    "  def call(self, inputs):\n",
    "    return tf.tile(inputs[:, -1:, :], [1, future_target, 1])\n",
    "\n",
    "baseline = MultiStepLastBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c832b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "    print(y_train_multi.shape)\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = baseline.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['Baseline'] = Mean_mae\n",
    "multi_test_performance['Baseline'] = baseline.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f1b2e",
   "metadata": {},
   "source": [
    "### LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb12bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(future_target*num_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af5c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_lstm_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_lstm_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['LSTM'] = Mean_mae\n",
    "multi_test_performance['LSTM'] = multi_lstm_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da92cd6",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b20ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, dense_units]\n",
    "    #tf.keras.layers.Dense(64, activation='relu'),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(future_target*num_features,kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([future_target, num_features])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf9659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_conv_model, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_conv_model.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN'] = Mean_mae\n",
    "multi_test_performance['CNN'] = multi_conv_model.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7b274",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65710c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cnn_lstm = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.Conv1D(filters=512, kernel_size=3, activation='relu', input_shape=(past_history, num_features)),\n",
    "    #tf.keras.layers.Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.RepeatVector(future_target),\n",
    "    tf.keras.layers.LSTM(200, return_sequences=True),\n",
    "    #tf.compat.v1.keras.layers.CuDNNLSTM(200,return_sequences=True),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(100, activation='relu')),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_features))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab2c42ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 5, 512)            26624     \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 1, 512)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " repeat_vector_9 (RepeatVect  (None, 5, 512)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 5, 200)            570400    \n",
      "                                                                 \n",
      " time_distributed_18 (TimeDi  (None, 5, 100)           20100     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_19 (TimeDi  (None, 5, 17)            1717      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 618,841\n",
      "Trainable params: 618,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_cnn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c68317db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_val_list = {}\n",
    "for fold, (train_index, test_index) in enumerate(splits.split(X_multi)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    x_train_multi, x_val_multi = X_multi[train_index], X_multi[test_index]\n",
    "    y_train_multi, y_val_multi = y_multi[train_index], y_multi[test_index]\n",
    "    print('Observations: %d' % (len(x_train_multi) + len(x_val_multi)))\n",
    "    print('Training Observations: %d' % (len(x_train_multi)))\n",
    "    print('Testing Observations: %d' % (len(x_val_multi)))\n",
    "    train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "    train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "\n",
    "    val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "    val_data_multi = val_data_multi.batch(batch_size).repeat()\n",
    "    \n",
    "    history = compile_and_fit(multi_cnn_lstm, train_data_multi, val_data_multi)\n",
    "\n",
    "    evaluation_val_list [\"Fold {}\".format(fold)] = multi_cnn_lstm.evaluate(val_data_multi, steps=50)\n",
    "\n",
    "\n",
    "\n",
    "IPython.display.clear_output()\n",
    "mae = []\n",
    "# calculate the mean mae\n",
    "for v in evaluation_val_list.values():\n",
    "    mae.append(v[1])\n",
    "Mean_mae = mean(mae)\n",
    "multi_val_performance['CNN-LSTM'] = Mean_mae\n",
    "multi_test_performance['CNN-LSTM'] = multi_cnn_lstm.evaluate(test_data_multi, verbose=0, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f38ba8",
   "metadata": {},
   "source": [
    "### plot MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d11e972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(multi_test_performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = baseline.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v for v in multi_val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in multi_test_performance.values()]\n",
    "\n",
    "pyplot.ylabel('mean_absolute_error')\n",
    "pyplot.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "pyplot.bar(x + 0.17, test_mae, width, label='Test')\n",
    "pyplot.xticks(ticks=x, labels=multi_test_performance.keys(),\n",
    "           rotation=45)\n",
    "_ = pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44df9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
